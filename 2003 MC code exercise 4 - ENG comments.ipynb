{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a478dc-1318-4f47-880d-8dd27855633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fractal / Uniform Structure Generation Utilities ===\n",
    "# - Generate Menger-like fractal structures or simple uniform pore networks\n",
    "# - Provide masks for pore, surface, and boundary regions\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "NB6 = np.array([[1,0,0],[-1,0,0],[0,1,0],[0,-1,0],[0,0,1],[0,0,-1]], dtype=int)\n",
    "\n",
    "def make_generator_mask(k_keep: int):\n",
    "    # Keep k cells (True=solid) in order of farthest from center → ensures pore network\n",
    "    coords=[]\n",
    "    for z in range(3):\n",
    "        for y in range(3):\n",
    "            for x in range(3):\n",
    "                m = abs(x-1)+abs(y-1)+abs(z-1)\n",
    "                coords.append(((z,y,x), m))\n",
    "    coords.sort(key=lambda t: t[1], reverse=True)\n",
    "    gen = np.zeros((3,3,3), dtype=bool)\n",
    "    for i in range(k_keep):\n",
    "        (z,y,x),_ = coords[i]; gen[z,y,x]=True\n",
    "    return gen  # True=solid\n",
    "\n",
    "def build_menger(level=3, k_keep=20):\n",
    "    solid = np.ones((1,1,1), dtype=bool)\n",
    "    gen = make_generator_mask(k_keep)\n",
    "    for _ in range(level):\n",
    "        solid = np.kron(solid, gen)\n",
    "    return solid  # True=solid, False=pore\n",
    "\n",
    "def build_uniform(level=3):\n",
    "    n = 3**level\n",
    "    solid = np.ones((n,n,n), dtype=bool)\n",
    "    # Drill a cross-shaped main channel to form a uniform pore network (simplified)\n",
    "    w = max(2, n//12)  # channel width\n",
    "    solid[:, :, n//2-w:n//2+w] = False\n",
    "    solid[:, n//2-w:n//2+w, :] = False\n",
    "    solid[n//2-w:n//2+w, :, :] = False\n",
    "    return solid\n",
    "\n",
    "def masks_from_solid(solid: np.ndarray):\n",
    "    pore = ~solid\n",
    "    Z,Y,X = solid.shape\n",
    "    pad = np.pad(solid, 1, constant_values=False)\n",
    "    surf = np.zeros_like(solid, dtype=bool)\n",
    "    for dz,dy,dx in NB6:\n",
    "        neigh = pad[1+dz:1+dz+Z, 1+dy:1+dy+Y, 1+dx:1+dx+X]\n",
    "        surf |= (solid & (~neigh))  # Solid cell with adjacent pore = surface\n",
    "    bpore = np.zeros_like(pore, dtype=bool)\n",
    "    bpore[0,:,:]|=pore[0,:,:];  bpore[-1,:,:]|=pore[-1,:,:]\n",
    "    bpore[:,0,:]|=pore[:,0,:];  bpore[:,-1,:]|=pore[:,-1,:]\n",
    "    bpore[:,:,0]|=pore[:,:,0];  bpore[:,:,-1]|=pore[:,:,-1]\n",
    "    return pore, surf, bpore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c9695f-5c72-46c2-9e12-3bd41984f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Monte Carlo Step Kernel (Diffusion + Reaction) ===\n",
    "# - Initialize reactant/product fields\n",
    "# - Perform one Monte Carlo step: diffusion, reaction, and product release\n",
    "# - Track intrinsic (total reactions) and apparent (released products) rates\n",
    "\n",
    "def init_fields(solid: np.ndarray, n_atm=50):\n",
    "    pore, surf, bpore = masks_from_solid(solid)\n",
    "    A = np.zeros_like(solid, dtype=np.int32)  # reactant\n",
    "    P = np.zeros_like(solid, dtype=np.int32)  # product\n",
    "    A[bpore] = n_atm  # external atmosphere layer\n",
    "    return pore, surf, bpore, A, P\n",
    "\n",
    "def mcs_step_numba(solid, pore, bpore, A, P, Ndif=1, Pr=0.1):\n",
    "    Z,Y,X = solid.shape\n",
    "    intrinsic = 0\n",
    "    apparent  = 0\n",
    "    idx = np.array(np.where(pore)).T\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    for z,y,x in idx:\n",
    "        occ = A[z,y,x] + P[z,y,x]\n",
    "        if occ <= 0: \n",
    "            continue\n",
    "        is_A = (rng.integers(occ) < A[z,y,x])\n",
    "        dz,dy,dx = NB6[rng.integers(6)]\n",
    "\n",
    "        # Move up to Ndif steps straight (through pore only, stop if solid is encountered)\n",
    "        zn,yn,xn = z,y,x\n",
    "        steps=0\n",
    "        while steps < Ndif:\n",
    "            z2,y2,x2 = zn+dz, yn+dy, xn+dx\n",
    "            if not (0<=z2<Z and 0<=y2<Y and 0<=x2<X): break\n",
    "            if solid[z2,y2,x2]: break\n",
    "            zn,yn,xn = z2,y2,x2\n",
    "            steps += 1\n",
    "\n",
    "        # Movement acceptance probability P_d (prefer destination with lower occupancy)\n",
    "        n_src = A[z,y,x] + P[z,y,x]\n",
    "        n_dst = A[zn,yn,xn] + P[zn,yn,xn]\n",
    "        Pd = np.exp(-(n_dst - n_src))\n",
    "        Pd = 1.0 if Pd>1 else Pd\n",
    "        if rng.random() < Pd:\n",
    "            if is_A: A[z,y,x]-=1; A[zn,yn,xn]+=1\n",
    "            else:    P[z,y,x]-=1; P[zn,yn,xn]+=1\n",
    "            z,y,x = zn,yn,xn\n",
    "\n",
    "        # Reaction occurs when A is adjacent to surface\n",
    "        if is_A and A[z,y,x]>0:\n",
    "            touched = False\n",
    "            for dz2,dy2,dx2 in NB6:\n",
    "                zz,yy,xx = z+dz2, y+dy2, x+dx2\n",
    "                if 0<=zz<Z and 0<=yy<Y and 0<=xx<X and solid[zz,yy,xx]:\n",
    "                    touched=True; break\n",
    "            if touched and rng.random()<Pr:\n",
    "                A[z,y,x]-=1; P[z,y,x]+=1\n",
    "                intrinsic += 1\n",
    "\n",
    "        # Products in boundary pores are released (measured as apparent rate)\n",
    "        if bpore[z,y,x] and P[z,y,x]>0:\n",
    "            apparent += P[z,y,x]\n",
    "            P[z,y,x] = 0\n",
    "\n",
    "    return intrinsic, apparent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea2d9c-d563-40fe-a153-ae08b26d654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Simulation Runner & Parameter Sweeps ===\n",
    "# - run_sim_numba: Run Monte Carlo simulation and return steady-state rates\n",
    "# - sweep_Pr_curves: Sweep reaction probability (Pr) to study rate dependence\n",
    "# - sweep_D_opt: Sweep fractal dimension candidates (via k_keep) to find optimal Df\n",
    "\n",
    "def run_sim_numba(solid, Ndif=1, Pr=0.1, mcs_total=1200, mcs_burn=600, n_atm=50):\n",
    "    pore, surf, bpore, A, P = init_fields(solid, n_atm=n_atm)\n",
    "    intr_hist=[]; app_hist=[]\n",
    "    for _ in range(mcs_total):\n",
    "        intr, app = mcs_step_numba(solid, pore, bpore, A, P, Ndif=Ndif, Pr=Pr)\n",
    "        intr_hist.append(intr); app_hist.append(app)\n",
    "    intr_ss = np.mean(intr_hist[mcs_burn:])\n",
    "    app_ss  = np.mean(app_hist[mcs_burn:])\n",
    "    return intr_ss, app_ss, np.array(intr_hist), np.array(app_hist)\n",
    "\n",
    "def sweep_Pr_curves(struct=\"fractal\", level=3, k_keep=20, Ndif=1, Pr_list=None):\n",
    "    if Pr_list is None:\n",
    "        Pr_list = np.geomspace(5e-3, 1.0, 8)\n",
    "    rates=[]\n",
    "    for Pr in Pr_list:\n",
    "        solid = build_menger(level, k_keep) if struct==\"fractal\" else build_uniform(level)\n",
    "        intr, app, *_ = run_sim_numba(solid, Ndif=Ndif, Pr=Pr, mcs_total=1200, mcs_burn=600, n_atm=50)\n",
    "        rates.append(app)\n",
    "    return np.array(Pr_list), np.array(rates)\n",
    "\n",
    "def sweep_D_opt(level=3, k_values=(12,14,16,18,20,22,24), Ndif=10, Pr=0.1):\n",
    "    Ds=[]; rates=[]\n",
    "    for k in k_values:\n",
    "        solid = build_menger(level, k)\n",
    "        intr, app, *_ = run_sim_numba(solid, Ndif=Ndif, Pr=Pr, mcs_total=1000, mcs_burn=500, n_atm=50)\n",
    "        Ds.append(np.log(k)/np.log(3)); rates.append(app)\n",
    "    return np.array(Ds), np.array(rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caee5de-9229-4c06-ada0-9b75a219004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 4: Optimal fractal dimension search\n",
    "# - Sweep different k_keep values (mapping to Df)\n",
    "# - Identify the Df that maximizes apparent rate\n",
    "# ==========================================================\n",
    "# === Step 4: Monte Carlo diffusion/reaction kernel (Guo & Keil 2003 rules) ===\n",
    "\n",
    "# If already defined in a previous cell, no need to redefine\n",
    "rng = np.random.default_rng(0)\n",
    "NB6 = np.array([[1,0,0],[-1,0,0],[0,1,0],[0,-1,0],[0,0,1],[0,0,-1]], dtype=int)\n",
    "\n",
    "\n",
    "\n",
    "# --- (Optional) Quick test for fast debugging ---\n",
    "# If no solid structure exists yet, you can uncomment the following example\n",
    "# to quickly build a uniform structure and run a short test.\n",
    "#\n",
    "# def build_uniform(level=3):\n",
    "#     n = 3**level; solid = np.ones((n,n,n), bool); w = max(2, n//12)\n",
    "#     solid[:,:,n//2-w:n//2+w] = False\n",
    "#     solid[:,n//2-w:n//2+w,:] = False\n",
    "#     solid[n//2-w:n//2+w,:,:] = False\n",
    "#     return solid\n",
    "#\n",
    "# solid = build_uniform(level=3)\n",
    "# intr_ss, app_ss, intr_hist, app_hist = run_sim_numba(\n",
    "#     solid, Ndif=10, Pr=0.1,\n",
    "#     mcs_total=400, mcs_burn=200, n_atm=50\n",
    "# )\n",
    "# print(\"steady intrinsic:\", intr_ss, \"steady apparent:\", app_ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92940d0-dd4f-473b-bab0-d2fa683b8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 2a: Mean Square Displacement (MSD) analysis\n",
    "# - Compare diffusion in uniform vs fractal structures\n",
    "# - MSD helps characterize transport regimes\n",
    "# ==========================================================\n",
    "# === Step 2a: MSD (Mean Squared Displacement) for ghost walkers ===\n",
    "# - Insert this block right after Step 4 (numba kernel)\n",
    "# ==========================================================\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "# If NB6 is already defined above, no need to redefine.\n",
    "# NB6 = np.array([[1,0,0],[-1,0,0],[0,1,0],[0,-1,0],[0,0,1],[0,0,-1]], dtype=np.int32)\n",
    "\n",
    "@njit\n",
    "def _msd_walkers_numba(pore, coords, steps=400, n_walkers=300, Ndif=1, seed=0):\n",
    "    \"\"\"\n",
    "    pore: bool[Z,Y,X] (True=pore)\n",
    "    coords: int32[Npore,3] (list of pore coordinates)\n",
    "    steps: number of time steps\n",
    "    n_walkers: number of ghost walkers (do not affect concentration/reaction)\n",
    "    Ndif: maximum number of straight steps in one move (Guo’s Ndif rule)\n",
    "    seed: random seed\n",
    "    return: msd[steps] (average r^2 at each t)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    Z, Y, X = pore.shape\n",
    "    ncoords = coords.shape[0]\n",
    "\n",
    "    # Initialize start/current positions\n",
    "    starts = np.empty((n_walkers, 3), np.int32)\n",
    "    pos    = np.empty((n_walkers, 3), np.int32)\n",
    "    for i in range(n_walkers):\n",
    "        j = np.random.randint(ncoords)\n",
    "        starts[i,0] = coords[j,0]; starts[i,1] = coords[j,1]; starts[i,2] = coords[j,2]\n",
    "        pos[i,0]    = coords[j,0]; pos[i,1]    = coords[j,1]; pos[i,2]    = coords[j,2]\n",
    "\n",
    "    msd = np.zeros(steps, dtype=np.float64)\n",
    "\n",
    "    for t in range(steps):\n",
    "        sum_r2 = 0.0\n",
    "        for i in range(n_walkers):\n",
    "            dz,dy,dx = NB6[np.random.randint(6)]\n",
    "            z = pos[i,0]; y = pos[i,1]; x = pos[i,2]\n",
    "            zn,yn,xn = z,y,x\n",
    "\n",
    "            # Move up to Ndif steps (stop if solid is hit)\n",
    "            k = 0\n",
    "            while k < Ndif:\n",
    "                z2 = zn + dz; y2 = yn + dy; x2 = xn + dx\n",
    "                if not (0 <= z2 < Z and 0 <= y2 < Y and 0 <= x2 < X):\n",
    "                    break\n",
    "                if not pore[z2, y2, x2]:  # stop if solid\n",
    "                    break\n",
    "                zn,yn,xn = z2,y2,x2\n",
    "                k += 1\n",
    "\n",
    "            # Update position\n",
    "            pos[i,0] = zn; pos[i,1] = yn; pos[i,2] = xn\n",
    "\n",
    "            # Accumulate r^2\n",
    "            dz0 = pos[i,0] - starts[i,0]\n",
    "            dy0 = pos[i,1] - starts[i,1]\n",
    "            dx0 = pos[i,2] - starts[i,2]\n",
    "            sum_r2 += dz0*dz0 + dy0*dy0 + dx0*dx0\n",
    "\n",
    "        msd[t] = sum_r2 / n_walkers\n",
    "\n",
    "    return msd\n",
    "\n",
    "def compute_msd(solid, steps=400, n_walkers=300, Ndif=1, seed=0):\n",
    "    \"\"\"\n",
    "    Wrapper: extract pore from solid (True=solid) and compute MSD\n",
    "    \"\"\"\n",
    "    pore, _, _ = masks_from_solid(solid)  # reuse existing function\n",
    "    coords = np.argwhere(pore).astype(np.int32)\n",
    "    msd = _msd_walkers_numba(pore, coords, steps=steps, n_walkers=n_walkers, Ndif=Ndif, seed=seed)\n",
    "    t = np.arange(1, steps+1, dtype=np.float64)\n",
    "    return t, msd\n",
    "\n",
    "def plot_msd_compare(level=3, k_keep=18, steps=400, n_walkers=300, Ndif=10, seed=0):\n",
    "    \"\"\"\n",
    "    Compare Uniform vs Fractal MSD under identical conditions (log–log plot)\n",
    "    \"\"\"\n",
    "    solid_fractal = build_menger(level=level, k_keep=k_keep)\n",
    "    solid_uniform = build_uniform(level=level)\n",
    "\n",
    "    t, msd_u = compute_msd(solid_uniform, steps=steps, n_walkers=n_walkers, Ndif=Ndif, seed=seed)\n",
    "    _, msd_f = compute_msd(solid_fractal, steps=steps, n_walkers=n_walkers, Ndif=Ndif, seed=seed+1)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.loglog(t, msd_u, label=\"Uniform\")\n",
    "    plt.loglog(t, msd_f, label=\"Fractal\")\n",
    "    plt.xlabel(\"t (MC steps)\")\n",
    "    plt.ylabel(\"MSD = ⟨r²(t)⟩\")\n",
    "    plt.title(f\"MSD vs t (Ndif={Ndif}, level={level}, k_keep={k_keep})\")\n",
    "    plt.legend(); plt.grid(True, which=\"both\", ls=\":\")\n",
    "    plt.show()\n",
    "\n",
    "    # Estimate slope (α) roughly: use linear region in later steps\n",
    "    lo = steps//3; hi = steps-1\n",
    "    s_u = np.polyfit(np.log(t[lo:hi]), np.log(msd_u[lo:hi]), 1)[0]\n",
    "    s_f = np.polyfit(np.log(t[lo:hi]), np.log(msd_f[lo:hi]), 1)[0]\n",
    "    print(f\"slope α (Uniform) ≈ {s_u:.2f},   slope α (Fractal) ≈ {s_f:.2f}\")\n",
    "\n",
    "\n",
    "# 1) Basic MSD comparison (Knudsen regime recommended: Ndif=10)\n",
    "plot_msd_compare(level=3, k_keep=18, steps=400, n_walkers=300, Ndif=10)\n",
    "\n",
    "# 2) Change Df to observe effect (e.g., rougher fractal)\n",
    "plot_msd_compare(level=3, k_keep=22, steps=400, n_walkers=300, Ndif=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc395ca4-e855-444a-a039-1568b5a4e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 2b: Residence Time Distribution (RTD) analysis\n",
    "# - Probe how long walkers spend inside pores before exiting\n",
    "# - Reveals transport efficiency differences\n",
    "# ==========================================================\n",
    "# === Step 2b: Residence Time Distribution (RTD) ===\n",
    "\n",
    "def simulate_RTD(solid, Ndif=10, Pr=0.1, n_particles=500, max_steps=2000, seed=0):\n",
    "    \"\"\"\n",
    "    Inject multiple particles from boundary pores → track their 'residence time'\n",
    "    until they either exit the boundary or react into product P and leave.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    pore, surf, bpore, A, P = init_fields(solid, n_atm=0)  # no external atmosphere; particles injected directly\n",
    "    times = []\n",
    "\n",
    "    for _ in range(n_particles):\n",
    "        # Initial position: randomly choose one boundary pore\n",
    "        bz, by, bx = np.array(np.argwhere(bpore))[rng.integers(bpore.sum())]\n",
    "        z, y, x = bz, by, bx\n",
    "        t = 0\n",
    "        alive = True\n",
    "\n",
    "        while alive and t < max_steps:\n",
    "            t += 1\n",
    "            # Random movement direction\n",
    "            dz, dy, dx = NB6[rng.integers(6)]\n",
    "            z2, y2, x2 = z+dz, y+dy, x+dx\n",
    "\n",
    "            if not (0 <= z2 < solid.shape[0] and 0 <= y2 < solid.shape[1] and 0 <= x2 < solid.shape[2]):\n",
    "                # Exited outside the boundary → record residence time\n",
    "                times.append(t)\n",
    "                alive = False\n",
    "                break\n",
    "\n",
    "            if solid[z2,y2,x2]:\n",
    "                # Collision with wall → remain in place\n",
    "                continue\n",
    "\n",
    "            # Move\n",
    "            z, y, x = z2, y2, x2\n",
    "\n",
    "            # Reaction if touching surface (probability Pr)\n",
    "            touched = False\n",
    "            for dz2, dy2, dx2 in NB6:\n",
    "                zz, yy, xx = z+dz2, y+dy2, x+dx2\n",
    "                if 0 <= zz < solid.shape[0] and 0 <= yy < solid.shape[1] and 0 <= xx < solid.shape[2]:\n",
    "                    if solid[zz,yy,xx]:\n",
    "                        touched = True\n",
    "                        break\n",
    "            if touched and rng.random() < Pr:\n",
    "                # Assume particle reacted into product → exits immediately\n",
    "                times.append(t)\n",
    "                alive = False\n",
    "                break\n",
    "\n",
    "    return np.array(times)\n",
    "\n",
    "def plot_RTD_compare(level=3, k_keep=18, Ndif=10, Pr=0.1,\n",
    "                     n_particles=500, max_steps=2000):\n",
    "    \"\"\"\n",
    "    Compare RTD (Residence Time Distribution) between Uniform vs Fractal structures\n",
    "    \"\"\"\n",
    "    solid_uni = build_uniform(level)\n",
    "    solid_frac = build_menger(level, k_keep=k_keep)\n",
    "\n",
    "    t_uni = simulate_RTD(solid_uni, Ndif=Ndif, Pr=Pr,\n",
    "                         n_particles=n_particles, max_steps=max_steps)\n",
    "    t_frac = simulate_RTD(solid_frac, Ndif=Ndif, Pr=Pr,\n",
    "                          n_particles=n_particles, max_steps=max_steps)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    bins = np.linspace(0, max_steps, 40)\n",
    "    plt.hist(t_uni, bins=bins, density=True, alpha=0.5, label=\"Uniform\")\n",
    "    plt.hist(t_frac, bins=bins, density=True, alpha=0.5, label=f\"Fractal (k_keep={k_keep})\")\n",
    "    plt.xlabel(\"Residence time (steps)\")\n",
    "    plt.ylabel(\"Probability density\")\n",
    "    plt.title(\"RTD comparison\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Mean Residence Time (MRT) — Uniform: {np.mean(t_uni):.1f}, Fractal: {np.mean(t_frac):.1f}\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# STEP 2b: Residence Time Distribution (RTD) analysis\n",
    "# - Probe how long walkers spend inside pores before exiting\n",
    "# - Reveals transport efficiency differences\n",
    "# ==========================================================\n",
    "# Step 2b test\n",
    "plot_RTD_compare(level=3, k_keep=18, Ndif=10, Pr=0.1,\n",
    "                 n_particles=500, max_steps=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e012a-805e-40b6-b216-9ba9edc72ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 3: Concentration profiles (A vs P)\n",
    "# - Visualize distribution of reactant (A) and product (P)\n",
    "# - Compare uniform and fractal geometries slice-by-slice\n",
    "# ==========================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_concentration_profile(solid, Ndif=10, Pr=0.1,\n",
    "                               mcs_total=800, n_atm=50,\n",
    "                               slice_axis=0, slice_index=None):\n",
    "    \"\"\"\n",
    "    Run simulation and visualize final reactant (A) and product (P) distributions\n",
    "    on a 2D slice of the 3D catalyst.\n",
    "    Normalization added for better contrast in visualization.\n",
    "    \"\"\"\n",
    "    # Run simulation\n",
    "    pore, surf, bpore, A, P = init_fields(solid, n_atm=n_atm)\n",
    "    for _ in range(mcs_total):\n",
    "        mcs_step_numba(solid, pore, bpore, A, P, Ndif=Ndif, Pr=Pr)\n",
    "\n",
    "    # Select slice index (middle slice by default)\n",
    "    if slice_index is None:\n",
    "        slice_index = solid.shape[slice_axis] // 2  \n",
    "\n",
    "    if slice_axis == 0:\n",
    "        A_slice, P_slice = A[slice_index,:,:], P[slice_index,:,:]\n",
    "    elif slice_axis == 1:\n",
    "        A_slice, P_slice = A[:,slice_index,:], P[:,slice_index,:]\n",
    "    else:\n",
    "        A_slice, P_slice = A[:,:,slice_index], P[:,:,slice_index]\n",
    "\n",
    "    # --- Normalization for better contrast (0–1 scale) ---\n",
    "    A_slice = A_slice.astype(float)\n",
    "    P_slice = P_slice.astype(float)\n",
    "    if A_slice.max() > 0:\n",
    "        A_slice = A_slice / A_slice.max()\n",
    "    if P_slice.max() > 0:\n",
    "        P_slice = P_slice / P_slice.max()\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "    im0 = axes[0].imshow(A_slice, origin=\"lower\", cmap=\"Blues\", vmin=0, vmax=1)\n",
    "    axes[0].set_title(\"Reactant A (slice)\")\n",
    "    plt.colorbar(im0, ax=axes[0])\n",
    "\n",
    "    im1 = axes[1].imshow(P_slice, origin=\"lower\", cmap=\"Reds\", vmin=0, vmax=1)\n",
    "    axes[1].set_title(\"Product P (slice)\")\n",
    "    plt.colorbar(im1, ax=axes[1])\n",
    "\n",
    "    plt.suptitle(\"Concentration profile in catalyst slice\")\n",
    "    plt.show()\n",
    "\n",
    "# ==========================================================\n",
    "# TEST CASES: Uniform vs Fractal catalyst\n",
    "# ==========================================================\n",
    "\n",
    "# Uniform solid (simple channel-like pore)\n",
    "solid_uni = build_uniform(level=3)\n",
    "\n",
    "# Fractal solid (Menger sponge-like structure)\n",
    "solid_frac = build_menger(level=3, k_keep=18)\n",
    "\n",
    "# Run with stronger parameters to highlight contrast\n",
    "print(\"=== Uniform Catalyst ===\")\n",
    "plot_concentration_profile(solid_uni, Ndif=15, Pr=0.5,\n",
    "                           mcs_total=20000, n_atm=200, slice_axis=0)\n",
    "\n",
    "print(\"=== Fractal Catalyst ===\")\n",
    "plot_concentration_profile(solid_frac, Ndif=15, Pr=0.5,\n",
    "                           mcs_total=20000, n_atm=200, slice_axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d0777-9c54-4806-993e-f191fee54498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 4: Optimal fractal dimension search\n",
    "# - Sweep different k_keep values (mapping to Df)\n",
    "# - Identify the Df that maximizes apparent rate\n",
    "# ==========================================================\n",
    "# === Step 4: Df sweep – find optimal fractal dimension ===\n",
    "\n",
    "\n",
    "def df_from_kkeep(k_keep, level=3):\n",
    "    \"\"\"\n",
    "    Estimate fractal dimension for a Menger-like structure.\n",
    "    Formula: Df ≈ log(k_keep)/log(3) (based on a single generation).\n",
    "    \"\"\"\n",
    "    return np.log(k_keep) / np.log(3)\n",
    "\n",
    "def sweep_Df(level=3, k_keep_list=(12,14,16,18,20,22,24),\n",
    "             Ndif=10, Pr=0.08, \n",
    "             mcs_total=1000, mcs_burn=500, n_atm=50):\n",
    "    \"\"\"\n",
    "    Sweep over different k_keep values → compute apparent rates vs estimated Df.\n",
    "    \"\"\"\n",
    "    Ds, rates = [], []\n",
    "    for kk in k_keep_list:\n",
    "        solid = build_menger(level, k_keep=kk)\n",
    "        intr, app, *_ = run_sim_numba(solid, Ndif=Ndif, Pr=Pr,\n",
    "                                      mcs_total=mcs_total, mcs_burn=mcs_burn,\n",
    "                                      n_atm=n_atm)\n",
    "        Ds.append(df_from_kkeep(kk, level=level))\n",
    "        rates.append(app)\n",
    "    return np.array(Ds), np.array(rates)\n",
    "\n",
    "def plot_optimal_D(level=3, k_keep_list=(12,14,16,18,20,22,24),\n",
    "                   Ndif=10, Pr=0.08,\n",
    "                   mcs_total=1000, mcs_burn=500, n_atm=50):\n",
    "    \"\"\"\n",
    "    Plot apparent rate vs fractal dimension and identify the optimal Df.\n",
    "    \"\"\"\n",
    "    Ds, rates = sweep_Df(level, k_keep_list,\n",
    "                         Ndif=Ndif, Pr=Pr,\n",
    "                         mcs_total=mcs_total, mcs_burn=mcs_burn,\n",
    "                         n_atm=n_atm)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.plot(Ds, rates, \"o-\", label=f\"Ndif={Ndif}, Pr={Pr}\")\n",
    "    plt.xlabel(\"Fractal dimension $D_f$\")\n",
    "    plt.ylabel(\"Apparent rate (arb. units)\")\n",
    "    plt.title(\"Search for optimal $D_f$\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    idx = np.argmax(rates)\n",
    "    print(f\"Optimal Df ≈ {Ds[idx]:.2f}, rate = {rates[idx]:.3f}\")\n",
    "\n",
    "# ==========================================================\n",
    "# STEP 4: Optimal fractal dimension search\n",
    "# - Sweep different k_keep values (mapping to Df)\n",
    "# - Identify the Df that maximizes apparent rate\n",
    "# ==========================================================\n",
    "# Step 4 test\n",
    "plot_optimal_D(level=3,\n",
    "               k_keep_list=[12,14,16,18,20,22,24],\n",
    "               Ndif=10, Pr=0.08,\n",
    "               mcs_total=1200, mcs_burn=600, n_atm=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81881667-2fee-404b-a126-62892bbfbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 5: Sweep over reaction probability (Pr)\n",
    "# - Analyze how the probability of reaction at the surface impacts the rate\n",
    "# - Explore the interplay between diffusion and reactivity\n",
    "# ==========================================================\n",
    "# === Step 5: Effect of reaction probability (Pr) on optimal Df ===\n",
    "def plot_Pr_sweep(level=3, k_keep_list=(12,14,16,18,20,22,24),\n",
    "                  Ndif=10, Pr_list=(0.03,0.05,0.08,0.12,0.2),\n",
    "                  mcs_total=800, mcs_burn=400, n_atm=50):\n",
    "    \"\"\"\n",
    "    Sweep across multiple reaction probabilities (Pr) and plot\n",
    "    apparent rate vs fractal dimension curves to compare how\n",
    "    reactivity influences the optimal Df.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for Pr in Pr_list:\n",
    "        Ds, rates = sweep_Df(level=level, k_keep_list=k_keep_list,\n",
    "                             Ndif=Ndif, Pr=Pr,\n",
    "                             mcs_total=mcs_total, mcs_burn=mcs_burn,\n",
    "                             n_atm=n_atm)\n",
    "        plt.plot(Ds, rates, \"o-\", label=f\"Pr={Pr}\")\n",
    "    plt.xlabel(\"Fractal dimension $D_f$\")\n",
    "    plt.ylabel(\"Apparent rate (arb. units)\")\n",
    "    plt.title(f\"Pr sweep (Ndif={Ndif})\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d40d91-d53b-4995-bb59-d5ad96e0189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 5: Sweep over reaction probability (Pr)\n",
    "# - Analyze how probability of reaction at surface impacts rate\n",
    "# - Interplay between diffusion and reactivity\n",
    "# ==========================================================\n",
    "# Step 5 test run\n",
    "plot_Pr_sweep(level=3,\n",
    "              k_keep_list=[12,14,16,18,20,22,24],\n",
    "              Ndif=10,\n",
    "              Pr_list=[0.03,0.05,0.08,0.12,0.2],\n",
    "              mcs_total=1000, mcs_burn=500, n_atm=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79797656-a805-4da8-985f-c3521395ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 6: Thiele modulus analytical model\n",
    "# - Connect fractal dimension Df to Knudsen diffusivity\n",
    "# - Compute effectiveness factor η(phi)\n",
    "# ==========================================================\n",
    "# === Step 6: Monte Carlo vs Thiele model comparison ===\n",
    "\n",
    "def thiele_knudsen_diffusivity(Df, r0=1.0):\n",
    "    # Simple model: D_K ~ (3 - Df)\n",
    "    return np.maximum(r0*(3.0 - Df), 1e-6)\n",
    "\n",
    "def thiele_modulus(Df, k=1.0, L=1.0):\n",
    "    DK = thiele_knudsen_diffusivity(Df)\n",
    "    return L * np.sqrt(k / DK)\n",
    "\n",
    "def thiele_eta(phi):\n",
    "    \"\"\"\n",
    "    Analytical effectiveness factor η(φ).\n",
    "    - Uses standard spherical catalyst approximation.\n",
    "    - Handles both scalar and array inputs.\n",
    "    \"\"\"\n",
    "    if np.isscalar(phi):\n",
    "        if phi < 1e-8: return 1.0\n",
    "        return (3.0/phi)*(1.0/np.tanh(phi) - 1.0/phi)\n",
    "    else:\n",
    "        phi = np.asarray(phi, dtype=float)\n",
    "        out = np.empty_like(phi)\n",
    "        small = phi < 1e-8\n",
    "        out[small] = 1.0\n",
    "        ps = phi[~small]\n",
    "        out[~small] = (3.0/ps)*(1.0/np.tanh(ps) - 1.0/ps)\n",
    "        return out\n",
    "\n",
    "def compare_MC_vs_Thiele(level=3, k_keep_list=(12,14,16,18,20,22,24),\n",
    "                         Ndif=10, Pr=0.08,\n",
    "                         mcs_total=800, mcs_burn=400, n_atm=50):\n",
    "    \"\"\"\n",
    "    Compare Monte Carlo simulation results vs Thiele modulus analytical model.\n",
    "    - Normalize both curves for direct comparison.\n",
    "    \"\"\"\n",
    "    # --- Monte Carlo ---\n",
    "    Ds, rates = sweep_Df(level, k_keep_list, Ndif, Pr,\n",
    "                         mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "\n",
    "    # --- Thiele model ---\n",
    "    Df_vals = np.linspace(min(Ds), max(Ds), 100)\n",
    "    phi = thiele_modulus(Df_vals, k=1.0, L=1.0)\n",
    "    eta = thiele_eta(phi)\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(Ds, rates/np.max(rates), \"o-\", label=\"Monte Carlo (normalized)\")\n",
    "    plt.plot(Df_vals, eta/np.max(eta), \"-\", label=\"Thiele model (normalized)\")\n",
    "    plt.xlabel(\"Fractal dimension $D_f$\")\n",
    "    plt.ylabel(\"Relative performance\")\n",
    "    plt.title(\"MC vs Thiele model\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f43c1-6f65-4141-9d38-9a52831fa391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 6: Thiele modulus analytical model\n",
    "# - Connect fractal dimension Df to Knudsen diffusivity\n",
    "# - Compute effectiveness factor η(phi)\n",
    "# ==========================================================\n",
    "# Step 6 test run\n",
    "compare_MC_vs_Thiele(level=3,\n",
    "                     k_keep_list=[12,14,16,18,20,22,24],\n",
    "                     Ndif=10, Pr=0.08,\n",
    "                     mcs_total=1000, mcs_burn=500, n_atm=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17a3ab-adea-4028-b95f-8a95cbe301ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 7–12: Heatmap and normalized analysis\n",
    "# - Sweep across Df and Pr\n",
    "# - Normalize by pore volume to remove trivial scaling\n",
    "# - Generate contour maps to locate optimal region\n",
    "# ==========================================================\n",
    "# === Step 7: Reaction probability (Pr) sweep ===\n",
    "def sweep_Pr_vs_D(level=3, k_keep_list=(12,14,16,18,20,22,24),\n",
    "                  Ndif=10, Pr_list=(0.03,0.05,0.08,0.12,0.2),\n",
    "                  mcs_total=800, mcs_burn=400, n_atm=50):\n",
    "    \"\"\"\n",
    "    Compare Df vs rate curves across multiple Pr conditions.\n",
    "    Each curve is normalized by its maximum rate.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for Pr in Pr_list:\n",
    "        Ds, rates = sweep_Df(level, k_keep_list, Ndif, Pr,\n",
    "                             mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "        rates_norm = rates / np.max(rates)  # normalize for each condition\n",
    "        plt.plot(Ds, rates_norm, \"o-\", label=f\"Pr={Pr}\")\n",
    "    plt.xlabel(\"Fractal dimension $D_f$\")\n",
    "    plt.ylabel(\"Normalized apparent rate\")\n",
    "    plt.title(f\"Effect of Pr on optimal Df (Ndif={Ndif})\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# ==========================================================\n",
    "# STEP 7–12: Heatmap and normalized analysis\n",
    "# - Sweep across Df and Pr\n",
    "# - Normalize by pore volume to remove trivial scaling\n",
    "# - Generate contour maps to locate optimal region\n",
    "# ==========================================================\n",
    "# Step 7 test run\n",
    "sweep_Pr_vs_D(level=3,\n",
    "              k_keep_list=[12,14,16,18,20,22,24],\n",
    "              Ndif=10,\n",
    "              Pr_list=[0.03,0.05,0.08,0.12,0.2],\n",
    "              mcs_total=1000, mcs_burn=500, n_atm=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba7945-34f8-4fd4-9983-cd8b146ab13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 8: Transient behavior (rate vs time)\n",
    "# - Track intrinsic & apparent reaction rates over simulation time\n",
    "# - Compare temporal evolution for uniform vs fractal structures\n",
    "# ==========================================================\n",
    "\n",
    "def plot_transient_rates(level=3, k_keep=18,\n",
    "                         Ndif=10, Pr=0.08,\n",
    "                         mcs_total=1500, n_atm=50):\n",
    "    \"\"\"\n",
    "    Track intrinsic & apparent reaction rates vs time steps.\n",
    "    Compare uniform vs fractal structures.\n",
    "    \"\"\"\n",
    "    solid_uni = build_uniform(level)\n",
    "    solid_frac = build_menger(level, k_keep=k_keep)\n",
    "\n",
    "    # Uniform run\n",
    "    _, _, intr_u, app_u = run_sim_numba(solid_uni, Ndif=Ndif, Pr=Pr,\n",
    "                                        mcs_total=mcs_total, n_atm=n_atm)\n",
    "    # Fractal run\n",
    "    _, _, intr_f, app_f = run_sim_numba(solid_frac, Ndif=Ndif, Pr=Pr,\n",
    "                                        mcs_total=mcs_total, n_atm=n_atm)\n",
    "\n",
    "    t = np.arange(mcs_total)\n",
    "\n",
    "    # Apparent rate vs time\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(t, app_u, \"-\", alpha=0.7, label=\"Uniform (apparent)\")\n",
    "    plt.plot(t, app_f, \"-\", alpha=0.7, label=f\"Fractal k_keep={k_keep} (apparent)\")\n",
    "    plt.xlabel(\"Monte Carlo steps\")\n",
    "    plt.ylabel(\"Apparent rate per step\")\n",
    "    plt.title(f\"Transient apparent rate (Ndif={Ndif}, Pr={Pr})\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Intrinsic rate vs time\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(t, intr_u, \"-\", alpha=0.7, label=\"Uniform (intrinsic)\")\n",
    "    plt.plot(t, intr_f, \"-\", alpha=0.7, label=f\"Fractal k_keep={k_keep} (intrinsic)\")\n",
    "    plt.xlabel(\"Monte Carlo steps\")\n",
    "    plt.ylabel(\"Intrinsic reaction events per step\")\n",
    "    plt.title(f\"Transient intrinsic rate (Ndif={Ndif}, Pr={Pr})\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Step 8 test run\n",
    "plot_transient_rates(level=3, k_keep=18,\n",
    "                     Ndif=10, Pr=0.08,\n",
    "                     mcs_total=1500, n_atm=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c37f0-4dcc-4a97-91ed-26f764dc5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 9: Normalize rates by pore volume\n",
    "# - Compute apparent rate per pore voxel\n",
    "# - Helps remove trivial scaling with pore size\n",
    "# ==========================================================\n",
    "\n",
    "def normalized_rate(solid, Ndif=10, Pr=0.08,\n",
    "                    mcs_total=1200, mcs_burn=600, n_atm=50):\n",
    "    \"\"\"\n",
    "    Run simulation and return apparent rate normalized by pore volume.\n",
    "    \"\"\"\n",
    "    pore = (~solid).sum()   # total pore voxel count\n",
    "    intr_ss, app_ss, _, _ = run_sim_numba(solid, Ndif=Ndif, Pr=Pr,\n",
    "                                          mcs_total=mcs_total,\n",
    "                                          mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "    return intr_ss/pore, app_ss/pore\n",
    "\n",
    "def sweep_normalized(level=3, k_keep_list=(12,14,16,18,20,22,24),\n",
    "                     Ndif=10, Pr=0.08,\n",
    "                     mcs_total=1200, mcs_burn=600, n_atm=50):\n",
    "    \"\"\"\n",
    "    Compute normalized apparent rate for several candidate fractal dimensions.\n",
    "    \"\"\"\n",
    "    Ds, rates = [], []\n",
    "    for kk in k_keep_list:\n",
    "        solid = build_menger(level, k_keep=kk)\n",
    "        intr_n, app_n = normalized_rate(solid, Ndif=Ndif, Pr=Pr,\n",
    "                                        mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "        Df = np.log(kk)/np.log(3)   # estimated fractal dimension\n",
    "        Ds.append(Df); rates.append(app_n)\n",
    "    return np.array(Ds), np.array(rates)\n",
    "\n",
    "def plot_normalized_optimal(level=3, k_keep_list=(12,14,16,18,20,22,24),\n",
    "                            Ndif=10, Pr=0.08,\n",
    "                            mcs_total=1200, mcs_burn=600, n_atm=50):\n",
    "    \"\"\"\n",
    "    Plot normalized apparent rate vs fractal dimension\n",
    "    and highlight the optimal Df.\n",
    "    \"\"\"\n",
    "    Ds, rates = sweep_normalized(level, k_keep_list=k_keep_list,\n",
    "                                 Ndif=Ndif, Pr=Pr,\n",
    "                                 mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(Ds, rates, \"o-\", label=\"Normalized apparent rate\")\n",
    "    plt.axvline(2.6, ls=\"--\", color=\"r\", alpha=0.6, label=\"~Reported optimum\")\n",
    "    plt.xlabel(\"Fractal dimension $D_f$\")\n",
    "    plt.ylabel(\"Normalized apparent rate (per pore voxel)\")\n",
    "    plt.title(\"Optimal fractal dimension (normalized by pore volume)\")\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    idx = np.argmax(rates)\n",
    "    print(f\"▶ Optimal Df ≈ {Ds[idx]:.2f}, normalized rate = {rates[idx]:.4f}\")\n",
    "\n",
    "\n",
    "# Step 9 test run\n",
    "plot_normalized_optimal(level=3,\n",
    "                        k_keep_list=[12,14,16,18,20,22,24],\n",
    "                        Ndif=10, Pr=0.08,\n",
    "                        mcs_total=1200, mcs_burn=600, n_atm=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690d865-1f5e-456b-b87c-1b81ba0296c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 10: 2D heatmap of (Df, Pr) space\n",
    "# - Sweep across fractal dimension (Df) and reaction probability (Pr)\n",
    "# - Visualize normalized apparent rate as a heatmap\n",
    "# ==========================================================\n",
    "\n",
    "def scan_Df_Pr(level=3, k_keep_list=(12,14,16,18,20,22,24),\n",
    "               Pr_list=(0.03,0.05,0.08,0.12,0.2),\n",
    "               Ndif=10, mcs_total=800, mcs_burn=400, n_atm=50):\n",
    "    \"\"\"\n",
    "    Sweep over (Df, Pr) and return normalized apparent rates.\n",
    "    \"\"\"\n",
    "    Ds = [np.log(k)/np.log(3) for k in k_keep_list]\n",
    "    Prs = list(Pr_list)\n",
    "    results = np.zeros((len(Prs), len(Ds)))\n",
    "\n",
    "    for i, Pr in enumerate(Prs):\n",
    "        for j, kk in enumerate(k_keep_list):\n",
    "            solid = build_menger(level, k_keep=kk)\n",
    "            _, app_n = normalized_rate(solid, Ndif=Ndif, Pr=Pr,\n",
    "                                       mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "            results[i,j] = app_n\n",
    "    return np.array(Ds), np.array(Prs), results\n",
    "\n",
    "def plot_heatmap(level=3, k_keep_list=(12,14,16,18,20,22,24),\n",
    "                 Pr_list=(0.03,0.05,0.08,0.12,0.2),\n",
    "                 Ndif=10, mcs_total=800, mcs_burn=400, n_atm=50):\n",
    "    \"\"\"\n",
    "    Generate a heatmap of normalized apparent rate vs (Df, Pr).\n",
    "    \"\"\"\n",
    "    Ds, Prs, R = scan_Df_Pr(level, k_keep_list, Pr_list,\n",
    "                             Ndif=Ndif, mcs_total=mcs_total,\n",
    "                             mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    im = plt.imshow(R, origin=\"lower\", aspect=\"auto\",\n",
    "                    extent=[min(Ds), max(Ds), min(Prs), max(Prs)],\n",
    "                    cmap=\"viridis\")\n",
    "    plt.colorbar(im, label=\"Normalized apparent rate\")\n",
    "    plt.xlabel(\"Fractal dimension $D_f$\")\n",
    "    plt.ylabel(\"Reaction probability Pr\")\n",
    "    plt.title(\"Heatmap of performance vs (Df, Pr)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Step 10 test run\n",
    "plot_heatmap(level=3,\n",
    "             k_keep_list=[12,14,16,18,20,22,24],\n",
    "             Pr_list=[0.03,0.05,0.08,0.12,0.2],\n",
    "             Ndif=10, mcs_total=800, mcs_burn=400, n_atm=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88273c73-170f-43a7-b460-7ad7ed0aa3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 11: Publication-style contour plot with optimum marker\n",
    "# - Generate a smoothed contour map of performance in (Df, Pr) space\n",
    "# - Highlight the optimal condition with a red marker\n",
    "# ==========================================================\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def plot_contour_with_optimum(level=3, \n",
    "                              k_keep_list=(12,14,16,18,20,22,24),\n",
    "                              Pr_list=(0.03,0.05,0.08,0.12,0.2),\n",
    "                              Ndif=10, mcs_total=800, mcs_burn=400, n_atm=80):\n",
    "    Ds, Prs, R = scan_Df_Pr(level, k_keep_list, Pr_list,\n",
    "                             Ndif=Ndif, mcs_total=mcs_total,\n",
    "                             mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "\n",
    "    # Smooth results for better-looking contours\n",
    "    R_smooth = gaussian_filter(R, sigma=1.0)\n",
    "\n",
    "    # Locate optimum point\n",
    "    idx = np.unravel_index(np.argmax(R_smooth), R_smooth.shape)\n",
    "    Pr_opt = Prs[idx[0]]\n",
    "    Df_opt = Ds[idx[1]]\n",
    "    R_opt  = R_smooth[idx]\n",
    "\n",
    "    # Contour plot\n",
    "    plt.figure(figsize=(7,5))\n",
    "    cs = plt.contourf(Ds, Prs, R_smooth, levels=15, cmap=\"viridis\")\n",
    "    plt.colorbar(cs, label=\"Normalized apparent rate\")\n",
    "\n",
    "    # Overlay contour lines\n",
    "    plt.contour(Ds, Prs, R_smooth, levels=6, colors=\"k\", linewidths=0.5)\n",
    "\n",
    "    # Mark optimum\n",
    "    plt.plot(Df_opt, Pr_opt, \"ro\", markersize=8, \n",
    "             label=f\"Optimum Df={Df_opt:.2f}, Pr={Pr_opt:.2f}\")\n",
    "\n",
    "    plt.xlabel(\"Fractal dimension $D_f$\")\n",
    "    plt.ylabel(\"Reaction probability Pr\")\n",
    "    plt.title(\"Contour map of performance vs (Df, Pr)\")\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"▶ Optimum at Df={Df_opt:.2f}, Pr={Pr_opt:.2f}, Rate={R_opt:.3f}\")\n",
    "\n",
    "# Step 11 test run\n",
    "plot_contour_with_optimum(level=3,\n",
    "                          k_keep_list=[12,14,16,18,20,22,24],\n",
    "                          Pr_list=[0.03,0.05,0.08,0.12,0.2],\n",
    "                          Ndif=10, mcs_total=1000, mcs_burn=500, n_atm=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4ccb5-1e61-4d86-9de1-c28ac3f80b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 12: Combined figure (Df vs rate + Df–Pr contour)\n",
    "# - Left: Line plot of apparent rate vs fractal dimension (Df)\n",
    "# - Right: Contour plot of performance in (Df, Pr) space\n",
    "# - Highlight the global optimum\n",
    "# ==========================================================\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def plot_combined_fig(level=3,\n",
    "                      k_keep_list=(12,14,16,18,20,22,24),\n",
    "                      Pr_list=(0.03,0.05,0.08,0.12,0.2),\n",
    "                      Ndif=10, mcs_total=1000, mcs_burn=500, n_atm=80):\n",
    "    # --- 1) Line plot: Df vs Rate at a chosen Pr ---\n",
    "    chosen_Pr = 0.08  # select one mid-range value\n",
    "    Ds, rates = sweep_Df(level=level, k_keep_list=k_keep_list,\n",
    "                         Ndif=Ndif, Pr=chosen_Pr,\n",
    "                         mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "\n",
    "    # --- 2) Contour data: Df–Pr heatmap ---\n",
    "    Ds2, Prs, R = scan_Df_Pr(level=level, k_keep_list=k_keep_list, Pr_list=Pr_list,\n",
    "                             Ndif=Ndif, mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "    R_smooth = gaussian_filter(R, sigma=1.0)\n",
    "\n",
    "    # Find optimum\n",
    "    idx = np.unravel_index(np.argmax(R_smooth), R_smooth.shape)\n",
    "    Pr_opt = Prs[idx[0]]\n",
    "    Df_opt = Ds2[idx[1]]\n",
    "    R_opt  = R_smooth[idx]\n",
    "\n",
    "    # --- Combined plot layout ---\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    gs = GridSpec(1, 2, width_ratios=[1,1.2], figure=fig)\n",
    "\n",
    "    # (a) Left: line plot\n",
    "    ax1 = fig.add_subplot(gs[0,0])\n",
    "    ax1.plot(Ds, rates, \"o-\", label=f\"Pr={chosen_Pr}\")\n",
    "    ax1.axvline(Df_opt, color=\"r\", linestyle=\"--\", label=f\"Optimum Df={Df_opt:.2f}\")\n",
    "    ax1.set_xlabel(\"Fractal dimension $D_f$\")\n",
    "    ax1.set_ylabel(\"Normalized rate\")\n",
    "    ax1.set_title(\"(a) Df vs Rate\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # (b) Right: contour map\n",
    "    ax2 = fig.add_subplot(gs[0,1])\n",
    "    cs = ax2.contourf(Ds2, Prs, R_smooth, levels=15, cmap=\"viridis\")\n",
    "    fig.colorbar(cs, ax=ax2, label=\"Normalized apparent rate\")\n",
    "    ax2.contour(Ds2, Prs, R_smooth, levels=6, colors=\"k\", linewidths=0.5)\n",
    "    ax2.plot(Df_opt, Pr_opt, \"ro\", markersize=8, label=\"Optimum\")\n",
    "    ax2.set_xlabel(\"Fractal dimension $D_f$\")\n",
    "    ax2.set_ylabel(\"Reaction probability Pr\")\n",
    "    ax2.set_title(\"(b) Contour map\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"▶ Optimum at Df={Df_opt:.2f}, Pr={Pr_opt:.2f}, Rate={R_opt:.3f}\")\n",
    "\n",
    "# Step 12 test run\n",
    "plot_combined_fig(level=3,\n",
    "                  k_keep_list=[12,14,16,18,20,22,24],\n",
    "                  Pr_list=[0.03,0.05,0.08,0.12,0.2],\n",
    "                  Ndif=10, mcs_total=1000, mcs_burn=500, n_atm=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fb7e8-6c1a-4a0f-9a4e-e8f84c7102ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 13: Combined figure with caption\n",
    "# - Create line plot (Df vs rate) and contour plot (Df–Pr space)\n",
    "# - Generate a publication-style figure caption summarizing the findings\n",
    "# ==========================================================\n",
    "\n",
    "def plot_combined_with_caption(level=3,\n",
    "                               k_keep_list=(12,14,16,18,20,22,24),\n",
    "                               Pr_list=(0.03,0.05,0.08,0.12,0.2),\n",
    "                               Ndif=10, mcs_total=1000, mcs_burn=500, n_atm=80):\n",
    "    # --- Data preparation ---\n",
    "    chosen_Pr = 0.08\n",
    "    Ds, rates = sweep_Df(level=level, k_keep_list=k_keep_list,\n",
    "                         Ndif=Ndif, Pr=chosen_Pr,\n",
    "                         mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "\n",
    "    Ds2, Prs, R = scan_Df_Pr(level=level, k_keep_list=k_keep_list, Pr_list=Pr_list,\n",
    "                             Ndif=Ndif, mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "    R_smooth = gaussian_filter(R, sigma=1.0)\n",
    "    idx = np.unravel_index(np.argmax(R_smooth), R_smooth.shape)\n",
    "    Pr_opt, Df_opt, R_opt = Prs[idx[0]], Ds2[idx[1]], R_smooth[idx]\n",
    "\n",
    "    # --- Plot layout ---\n",
    "    fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "    # (a) Line plot\n",
    "    axes[0].plot(Ds, rates, \"o-\", label=f\"Pr={chosen_Pr}\")\n",
    "    axes[0].axvline(Df_opt, color=\"r\", linestyle=\"--\", label=f\"Optimum Df={Df_opt:.2f}\")\n",
    "    axes[0].set_xlabel(\"Fractal dimension $D_f$\")\n",
    "    axes[0].set_ylabel(\"Normalized rate\")\n",
    "    axes[0].set_title(\"(a) Df vs Rate\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # (b) Contour map\n",
    "    cs = axes[1].contourf(Ds2, Prs, R_smooth, levels=15, cmap=\"viridis\")\n",
    "    fig.colorbar(cs, ax=axes[1], label=\"Normalized apparent rate\")\n",
    "    axes[1].contour(Ds2, Prs, R_smooth, levels=6, colors=\"k\", linewidths=0.5)\n",
    "    axes[1].plot(Df_opt, Pr_opt, \"ro\", markersize=8, label=\"Optimum\")\n",
    "    axes[1].set_xlabel(\"Fractal dimension $D_f$\")\n",
    "    axes[1].set_ylabel(\"Reaction probability Pr\")\n",
    "    axes[1].set_title(\"(b) Contour map\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Publication-style caption ---\n",
    "    caption = (\n",
    "        \"Figure X. (a) Normalized reaction rate as a function of fractal dimension $D_f$ \"\n",
    "        f\"at fixed probability Pr={chosen_Pr}. The maximum occurs near $D_f={Df_opt:.2f}$. \"\n",
    "        \"(b) Contour map of normalized apparent reaction rate as a function of \"\n",
    "        \"fractal dimension $D_f$ and reaction probability Pr. \"\n",
    "        f\"The global optimum is located at $D_f={Df_opt:.2f}$ and Pr={Pr_opt:.2f}, \"\n",
    "        f\"with normalized rate ≈ {R_opt:.3f}. \"\n",
    "        \"These results illustrate the existence of an optimal fractal dimension \"\n",
    "        \"where the trade-off between increased surface area and diffusion/side-reaction limitations \"\n",
    "        \"is balanced.\"\n",
    "    )\n",
    "    print(caption)\n",
    "\n",
    "# Step 13 test run\n",
    "plot_combined_with_caption(level=3,\n",
    "                           k_keep_list=[12,14,16,18,20,22,24],\n",
    "                           Pr_list=[0.03,0.05,0.08,0.12,0.2],\n",
    "                           Ndif=10, mcs_total=1000, mcs_burn=500, n_atm=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dde1cd-a5e0-466a-b1af-8831cd629715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 14: Save figure to PNG/PDF\n",
    "# - Generate combined plots (Df vs rate + Df–Pr contour)\n",
    "# - Export results as high-resolution PNG and PDF\n",
    "# ==========================================================\n",
    "\n",
    "def save_combined_figure(level=3,\n",
    "                         k_keep_list=(12,14,16,18,20,22,24),\n",
    "                         Pr_list=(0.03,0.05,0.08,0.12,0.2),\n",
    "                         Ndif=10, mcs_total=1000, mcs_burn=500, n_atm=80,\n",
    "                         filename=\"figure_optimum\"):\n",
    "    # --- Data preparation ---\n",
    "    chosen_Pr = 0.08\n",
    "    Ds, rates = sweep_Df(level=level, k_keep_list=k_keep_list,\n",
    "                         Ndif=Ndif, Pr=chosen_Pr,\n",
    "                         mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "\n",
    "    Ds2, Prs, R = scan_Df_Pr(level=level, k_keep_list=k_keep_list, Pr_list=Pr_list,\n",
    "                             Ndif=Ndif, mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "    R_smooth = gaussian_filter(R, sigma=1.0)\n",
    "    idx = np.unravel_index(np.argmax(R_smooth), R_smooth.shape)\n",
    "    Pr_opt, Df_opt, R_opt = Prs[idx[0]], Ds2[idx[1]], R_smooth[idx]\n",
    "\n",
    "    # --- Plotting ---\n",
    "    fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "    # (a) Line plot\n",
    "    axes[0].plot(Ds, rates, \"o-\", label=f\"Pr={chosen_Pr}\")\n",
    "    axes[0].axvline(Df_opt, color=\"r\", linestyle=\"--\", label=f\"Optimum Df={Df_opt:.2f}\")\n",
    "    axes[0].set_xlabel(\"Fractal dimension $D_f$\")\n",
    "    axes[0].set_ylabel(\"Normalized rate\")\n",
    "    axes[0].set_title(\"(a) Df vs Rate\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # (b) Contour plot\n",
    "    cs = axes[1].contourf(Ds2, Prs, R_smooth, levels=15, cmap=\"viridis\")\n",
    "    fig.colorbar(cs, ax=axes[1], label=\"Normalized apparent rate\")\n",
    "    axes[1].contour(Ds2, Prs, R_smooth, levels=6, colors=\"k\", linewidths=0.5)\n",
    "    axes[1].plot(Df_opt, Pr_opt, \"ro\", markersize=8, label=\"Optimum\")\n",
    "    axes[1].set_xlabel(\"Fractal dimension $D_f$\")\n",
    "    axes[1].set_ylabel(\"Reaction probability Pr\")\n",
    "    axes[1].set_title(\"(b) Contour map\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- Save to PNG and PDF ---\n",
    "    png_file = f\"{filename}.png\"\n",
    "    pdf_file = f\"{filename}.pdf\"\n",
    "    fig.savefig(png_file, dpi=300, bbox_inches=\"tight\")\n",
    "    fig.savefig(pdf_file, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"✅ Figures saved as {png_file} and {pdf_file}\")\n",
    "\n",
    "# Step 14 test run\n",
    "save_combined_figure(level=3,\n",
    "                     k_keep_list=[12,14,16,18,20,22,24],\n",
    "                     Pr_list=[0.03,0.05,0.08,0.12,0.2],\n",
    "                     Ndif=10, mcs_total=1000, mcs_burn=500, n_atm=80,\n",
    "                     filename=\"Optimal_Fractal_Dimension\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d494b-6bc0-41ca-ba47-047556aaa631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 5: Sweep over reaction probability (Pr)\n",
    "# - Analyze how probability of reaction at surface impacts rate\n",
    "# - Explore interplay between diffusion and reactivity\n",
    "# ==========================================================\n",
    "# === Step 5: Pr sweep & regime visualization (uniform vs fractal, Ndif=1/10) ===\n",
    "\n",
    "def sweep_Pr_curves(struct=\"fractal\", level=3, k_keep=20, Ndif=1, Pr_list=None,\n",
    "                    mcs_total=1200, mcs_burn=600, n_atm=50, seed=0):\n",
    "    \"\"\"\n",
    "    Sweep reaction probability (Pr) for a given structure (uniform or fractal)\n",
    "    and return apparent rate curves at fixed Ndif.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if Pr_list is None:\n",
    "        Pr_list = np.geomspace(5e-3, 1.0, 10)\n",
    "    rates = []\n",
    "    for Pr in Pr_list:\n",
    "        # Generate structure\n",
    "        if struct == \"fractal\":\n",
    "            solid = build_menger(level, k_keep)\n",
    "        else:\n",
    "            solid = build_uniform(level)\n",
    "\n",
    "        # Run simulation\n",
    "        intr, app, *_ = run_sim_numba(solid, Ndif=Ndif, Pr=Pr, \n",
    "                                 mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "        rates.append(app)\n",
    "    return np.array(Pr_list), np.array(rates)\n",
    "\n",
    "def plot_regimes(level=3, k_keep=20, mcs_total=1200, mcs_burn=600, n_atm=50):\n",
    "    \"\"\"\n",
    "    Compare uniform vs fractal structures at Ndif=1 and Ndif=10.\n",
    "    - Plot log–log curves of apparent rate vs Pr\n",
    "    - Compute local slopes (low/mid/high Pr regions) to characterize regimes\n",
    "    \"\"\"\n",
    "    setups = [(\"uniform\", 1), (\"uniform\", 10), (\"fractal\", 1), (\"fractal\", 10)]\n",
    "    for struct, Ndif in setups:\n",
    "        Pr, rate = sweep_Pr_curves(struct=struct, level=level, k_keep=k_keep, Ndif=Ndif,\n",
    "                                   mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "        m = rate > 0\n",
    "        Pr, rate = Pr[m], rate[m]\n",
    "        if len(rate) == 0:\n",
    "            print(f\"[{struct}, Ndif={Ndif}] all-zero rates. Increase mcs_total/n_atm or widen Pr_list.\")\n",
    "            continue\n",
    "\n",
    "        # Plot log–log curve\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.plot(Pr, rate, \"o-\")\n",
    "        plt.xscale(\"log\"); plt.yscale(\"log\")\n",
    "        plt.title(f\"{struct}, Ndif={Ndif} — log(rate) vs log(Pr)\")\n",
    "        plt.xlabel(\"Pr\"); plt.ylabel(\"Apparent rate\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # Estimate slopes in low/mid/high Pr regions\n",
    "        def slope(lo, hi):\n",
    "            mask = (Pr>=lo) & (Pr<=hi)\n",
    "            if mask.sum() < 2: return np.nan\n",
    "            x = np.log10(Pr[mask]); y = np.log10(rate[mask])\n",
    "            a, b = np.polyfit(x, y, 1)\n",
    "            return a\n",
    "\n",
    "        s_low  = slope(5e-3, 3e-2)\n",
    "        s_mid  = slope(3e-2, 3e-1)\n",
    "        s_high = slope(3e-1, 1.0)\n",
    "        print(f\"[{struct}, Ndif={Ndif}] slopes  low≈{s_low:.2f}, mid≈{s_mid:.2f}, high≈{s_high:.2f}\")\n",
    "\n",
    "# Example run (may take some time):\n",
    "# plot_regimes(level=3, k_keep=20, mcs_total=1200, mcs_burn=600, n_atm=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda03bc-983d-41a2-a009-9cafbabb256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# STEP 6: Thiele modulus analytical model\n",
    "# - Connect fractal dimension Df to Knudsen diffusivity\n",
    "# - Compute effectiveness factor η(phi)\n",
    "# ==========================================================\n",
    "# === Step 6: Df sweep to find optimal D ===\n",
    "\n",
    "def df_from_kkeep(k_keep, level=3):\n",
    "    \"\"\"\n",
    "    Estimate fractal dimension for a Menger-like structure:\n",
    "    Df = log(k_keep) / log(3)  (single generation basis).\n",
    "    \"\"\"\n",
    "    return np.log(k_keep) / np.log(3)\n",
    "\n",
    "def sweep_Df(level=3, k_keep_list=(10, 15, 20), \n",
    "             Ndif=1, Pr=0.05, \n",
    "             mcs_total=600, mcs_burn=300, n_atm=20, seed=0):\n",
    "    \"\"\"\n",
    "    Compare apparent rates across different k_keep values\n",
    "    (corresponding to different fractal dimensions).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Ds, rates = [], []\n",
    "    for kk in k_keep_list:\n",
    "        solid = build_menger(level, k_keep=kk)\n",
    "        intr, app, *_ = run_sim_numba(solid, Ndif=Ndif, Pr=Pr,\n",
    "                                mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "        Ds.append(df_from_kkeep(kk, level=level))\n",
    "        rates.append(app)\n",
    "    return np.array(Ds), np.array(rates)\n",
    "\n",
    "def plot_optimal_D(level=3, k_keep_list=(8,12,15,18,20),\n",
    "                   Ndif=1, Pr=0.05, \n",
    "                   mcs_total=600, mcs_burn=300, n_atm=20):\n",
    "    \"\"\"\n",
    "    Plot apparent rate vs fractal dimension for different k_keep values\n",
    "    and highlight the optimal Df.\n",
    "    \"\"\"\n",
    "    Ds, rates = sweep_Df(level=level, k_keep_list=k_keep_list,\n",
    "                         Ndif=Ndif, Pr=Pr,\n",
    "                         mcs_total=mcs_total, mcs_burn=mcs_burn, n_atm=n_atm)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.plot(Ds, rates, \"o-\")\n",
    "    plt.xlabel(\"Fractal dimension $D_f$\")\n",
    "    plt.ylabel(\"Apparent rate (arb. units)\")\n",
    "    plt.title(f\"Ndif={Ndif}, Pr={Pr} — Optimal D search\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    idx = np.argmax(rates)\n",
    "    print(f\"Optimal Df ≈ {Ds[idx]:.2f}, rate = {rates[idx]:.4f}\")\n",
    "\n",
    "# Example: run for multiple Pr values\n",
    "k_keep_list = [12,14,16,18,20,22,24]  # Df ≈ 2.26 ~ 2.89\n",
    "\n",
    "for Pr in [0.03, 0.05, 0.08, 0.12, 0.2]:\n",
    "    plot_optimal_D(\n",
    "        level=3,\n",
    "        k_keep_list=k_keep_list,\n",
    "        Ndif=10,               # Knudsen regime\n",
    "        Pr=Pr,                 # sweep over different Pr\n",
    "        mcs_total=1200,\n",
    "        mcs_burn=600,\n",
    "        n_atm=80\n",
    "    )\n",
    "\n",
    "\n",
    "# === Step 6a: Add analytical Thiele modulus model ===\n",
    "\n",
    "def knudsen_diffusivity(Df, r0=1.0):\n",
    "    \"\"\"\n",
    "    Simple model: D_K ~ (3 - Df)\n",
    "    (Higher Df → more complex structure → smaller effective radius → lower D_K)\n",
    "    \"\"\"\n",
    "    return np.maximum(r0*(3.0 - Df), 1e-6)\n",
    "\n",
    "def thiele_modulus(Df, k=1.0, L=1.0):\n",
    "    \"\"\"\n",
    "    Compute Thiele modulus φ as a function of fractal dimension.\n",
    "    \"\"\"\n",
    "    DK = knudsen_diffusivity(Df)\n",
    "    return L * np.sqrt(k / DK)\n",
    "\n",
    "def eta_effectiveness(phi):\n",
    "    \"\"\"\n",
    "    Effectiveness factor η(φ) for first-order reaction in a spherical particle.\n",
    "    \"\"\"\n",
    "    if np.isscalar(phi):\n",
    "        if phi < 1e-8:\n",
    "            return 1.0\n",
    "        return (3.0/phi) * (1.0/np.tanh(phi) - 1.0/phi)\n",
    "    else:\n",
    "        phi = np.asarray(phi, dtype=float)\n",
    "        out = np.empty_like(phi)\n",
    "        small = phi < 1e-8\n",
    "        out[small] = 1.0\n",
    "        ps = phi[~small]\n",
    "        out[~small] = (3.0/ps) * (1.0/np.tanh(ps) - 1.0/ps)\n",
    "        return out\n",
    "\n",
    "# Analytical model: Df sweep & visualization\n",
    "Df_vals = np.linspace(2.0, 3.0, 100)\n",
    "phi = thiele_modulus(Df_vals, k=1.0, L=1.0)\n",
    "eta = eta_effectiveness(phi)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(Df_vals, eta, label=\"Effectiveness factor η(Df)\")\n",
    "plt.xlabel(\"Fractal dimension $D_f$\")\n",
    "plt.ylabel(\"η (relative efficiency)\")\n",
    "plt.title(\"Thiele modulus model vs Df\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# STEP 6b: Monte Carlo vs Thiele analytical model comparison\n",
    "# - Normalize MC simulation results and compare with η(Df)\n",
    "# ==========================================================\n",
    "Df_vals = np.linspace(2.0, 3.0, 100)\n",
    "phi = thiele_modulus(Df_vals, k=1.0, L=1.0)\n",
    "eta = eta_effectiveness(phi)\n",
    "\n",
    "# Monte Carlo results\n",
    "Ds, rates = sweep_Df(level=3, k_keep_list=[12,14,16,18,20,22,24],\n",
    "                     Ndif=10, Pr=0.08, mcs_total=1200, mcs_burn=600, n_atm=80)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(Ds, rates/rates.max(), \"o-\", label=\"MC simulation (normalized)\")\n",
    "plt.plot(Df_vals, eta/eta.max(), \"-\", label=\"Thiele modulus model\")\n",
    "plt.xlabel(\"Fractal dimension $D_f$\")\n",
    "plt.ylabel(\"Relative performance\")\n",
    "plt.legend()\n",
    "plt.title(\"MC vs Thiele model\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
